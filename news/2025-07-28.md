# AI Agents News - July 28, 2025

## Recent AI Agents Research & Scientific Developments (July 21-28, 2025)

### 1. **GEMMAS: Graph-based Evaluation Metrics for Multi-Agent Systems**
**Publication**: arXiv:2507.13190 (July 2025)  
**Source**: [https://arxiv.org/abs/2507.13190](https://arxiv.org/abs/2507.13190)

GEMMAS introduces a groundbreaking graph-based evaluation framework that models agent interactions as directed acyclic graphs to assess collaboration quality. The framework proposes two novel process-level metrics: Information Diversity Score (IDS) measuring semantic variation in inter-agent messages, and Unnecessary Path Ratio (UPR) quantifying redundant reasoning paths.

**Scientific Significance**: This addresses a critical gap in multi-agent evaluation where outcome-only metrics are insufficient. The research demonstrates that systems with only 2.1% difference in accuracy can differ by 12.8% in IDS and 80% in UPR, revealing substantial internal collaboration variations previously invisible to traditional metrics.

**Technical Details**: The framework captures both structural and semantic aspects of agent interactions, providing fine-grained analysis of decision-making processes across five benchmark evaluations.

---

### 2. **AI4Research: A Survey of Artificial Intelligence for Scientific Research**
**Publication**: arXiv:2507.01903 (July 2025)  
**Source**: [https://arxiv.org/abs/2507.01903](https://arxiv.org/abs/2507.01903)

This comprehensive survey introduces a systematic taxonomy classifying five mainstream tasks in AI4Research, driven by recent advances in LLMs like OpenAI-o1 and DeepSeek-R1 that demonstrate remarkable capabilities in logical reasoning and experimental coding for autonomous research processes.

**Scientific Significance**: Establishes the first comprehensive framework for AI-driven scientific research, identifying key gaps in automated experiment rigor and scalability while highlighting societal impact considerations. The work compiles extensive resources across multidisciplinary applications, data corpora, and tools.

**Technical Details**: The survey covers autonomous literature review, hypothesis generation, experimental design, and result interpretation across multiple scientific disciplines, providing a roadmap for AI systems that can conduct end-to-end research workflows.

---

### 3. **Google's AI Co-Scientist Multi-Agent System**
**Publication**: Google Research Blog (July 2025)  
**Source**: [https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/)

Google introduced AI co-scientist, a multi-agent system built on Gemini 2.0 designed as a virtual scientific collaborator that generates novel hypotheses and research proposals while mirroring the reasoning process of the scientific method.

**Scientific Significance**: Represents the first production-ready AI system capable of formulating demonstrably novel research hypotheses tailored to specific research objectives, moving beyond literature summarization to original knowledge generation.

**Technical Details**: The system integrates multiple specialized agents for literature analysis, hypothesis formation, and experimental protocol design, with validation showing capability to generate research proposals indistinguishable from human-generated ones in blind evaluations.

---

### 4. **Adaptive Multi-Agent RL with Graph Neural Networks for Dynamic Optimization**
**Publication**: MDPI Buildings (July 20, 2025)  
**Source**: [https://www.mdpi.com/2075-5309/15/14/2554](https://www.mdpi.com/2075-5309/15/14/2554)

This research introduces an adaptive MARL framework incorporating graph neural networks for dynamic optimization in complex facility management, specifically targeting sports buildings with heterogeneous operational requirements.

**Scientific Significance**: Achieves 13% improvement in operational efficiency over Centralized PPO (0.89 ± 0.02) and 9% enhancement in user satisfaction (0.85 ± 0.03) in simulated environments with 12 heterogeneous facilities, demonstrating practical scalability of graph-based multi-agent coordination.

**Technical Details**: The framework combines temporal graph convolution with multi-agent policy gradient methods, enabling dynamic adaptation to changing facility usage patterns and resource constraints through shared graph representations.

---

### 5. **Deep Research Agents: Systematic Examination and Roadmap**
**Publication**: arXiv:2506.18096 (June 2025, updated July 2025)  
**Source**: [https://arxiv.org/abs/2506.18096](https://arxiv.org/abs/2506.18096)

This work provides the first comprehensive analysis of Deep Research (DR) agents designed for complex, multi-turn informational research tasks through dynamic reasoning, adaptive long-horizon planning, and iterative tool use with structured analytical report generation.

**Scientific Significance**: Identifies critical limitations in current benchmarks including restricted external knowledge access, sequential execution inefficiencies, and misalignment between evaluation metrics and practical DR objectives. Proposes new evaluation frameworks specifically designed for research-oriented agents.

**Technical Details**: The study examines multi-hop information retrieval algorithms, iterative refinement mechanisms, and report structuring capabilities across multiple research domains, establishing performance baselines for future DR agent development.

---

### 6. **Memory System Advances in AI Agents**
**Publication**: MarkTechPost Technical Analysis (July 26, 2025)  
**Source**: [https://www.marktechpost.com/2025/07/26/how-memory-transforms-ai-agents-insights-and-leading-solutions-in-2025/](https://www.marktechpost.com/2025/07/26/how-memory-transforms-ai-agents-insights-and-leading-solutions-in-2025/)

Recent advances demonstrate 90% latency reduction and +18.5% improved recall accuracy in production memory systems for AI agents, with context windows expanding beyond 1M tokens enabling richer single-interaction processing.

**Scientific Significance**: Memory architecture improvements represent a fundamental breakthrough enabling agents to maintain long-term context and learn from experience, moving beyond reactive systems toward truly adaptive agents with persistent knowledge.

**Technical Details**: New memory frameworks integrate both short-term (working memory) and long-term (episodic/semantic) storage with optimized retrieval mechanisms, enabling agents to handle complex multi-session tasks with historical context awareness.

---

### 7. **Mobile-Bench: LLM-based Mobile Agent Evaluation**
**Publication**: arXiv:2407.00993 (July 2025)  
**Source**: [https://arxiv.org/html/2407.00993v1](https://arxiv.org/html/2407.00993v1)

Mobile-Bench introduces a comprehensive benchmark with 832 data entries across 200+ tasks for evaluating multi-APP collaboration scenarios, featuring the novel CheckPoint metric that assesses whether agents reach essential reasoning milestones.

**Scientific Significance**: Addresses the gap in mobile-specific agent evaluation by providing the first standardized benchmark for cross-application coordination tasks, revealing performance disparities invisible to traditional end-to-end success metrics.

**Technical Details**: The benchmark includes complex workflows requiring GUI understanding, multi-step planning across applications, and contextual reasoning about mobile interface states, with CheckPoint metrics tracking intermediate reasoning quality.

---

### 8. **Survey on LLM-based Agent Evaluation**
**Publication**: arXiv:2503.16416 (Updated July 2025)  
**Source**: [https://arxiv.org/abs/2503.16416](https://arxiv.org/abs/2503.16416)

This comprehensive survey analyzes agent evaluation across four dimensions: fundamental capabilities (planning, tool use, self-reflection, memory), application-specific benchmarks, generalist benchmarks, and evaluation frameworks, identifying critical gaps in cost-efficiency and safety assessment.

**Scientific Significance**: Establishes the first systematic framework for agent evaluation methodology, revealing that current approaches inadequately assess cost-efficiency, robustness, and fine-grained decision-making processes essential for production deployment.

**Technical Details**: The analysis covers 50+ evaluation frameworks and benchmarks, proposing standardized metrics for trajectory-level assessment, tool selection quality, and multi-turn reasoning consistency across diverse task domains.

---

## Key Themes and Future Directions

The research from July 21-28, 2025 reveals several critical trends:

1. **Process-Oriented Evaluation**: Moving beyond outcome metrics to assess internal reasoning quality and collaboration patterns
2. **Scientific Research Automation**: AI systems capable of autonomous hypothesis generation and experimental design
3. **Memory Architecture Advances**: Dramatic improvements in long-term context maintenance and retrieval efficiency
4. **Multi-Agent Coordination**: Enhanced frameworks for complex collaborative problem-solving with measurable performance gains
5. **Domain-Specific Benchmarks**: Recognition that general benchmarks inadequately assess specialized agent capabilities

These developments collectively indicate that AI agents are transitioning from proof-of-concept systems to production-ready tools capable of autonomous scientific research, complex reasoning, and sustained multi-session interactions.